%conclusion
Finally, we want to draw a conclusion. In our empirical section we found what was expected from a theoretical point of view. Bootstrap techniques can accurately estimate parameters and statistics even under small sample sizes. Furthermore, an extensive simulation of testing the mean showed that bootstrap-versions of the t-Test converge fast to the significance level in terms of Type-I-Error, although for some populations this took longer than for others, dependent on the sample sizes. This highlights one of the main drawbacks of bootstrap in general, namely that the sample itself has to be at least a littlebit representative in order to obtain proper bootstrap results. Nonetheless, with increasing sample sizes and increasing bootstrap iterations the significance level is reached. Also, the power of the t-Test was roughly the same in it's bootstrap versions as it was in it's actual version for nearly all situations. Both aspects demonstrate that bootstrapping tests can be a proper method in practice. Also, bootstrap is more flexible in practice in the sense that one has not to rely on the theoretical distribution function of the test statistic, since this is created with an empirical distribution function (which is again, in theory, converging almost sure to the actual distribution). With a simple regression problem we demonstrated computational complexity of bootstrap and applied different language implementations. Even for such a simple problem the computation time was quite high and increased in this specific case exponentially with the number of bootstrap iterations. As expected, the implementation in a lower-level language, namely C++, provided a huge advantage against R, being roughly $8$ times faster on median time. Although the time was still below a single second, this can be generalized since there exist many problems requiring much more computation time than a simple linear regression estimation. Since this paper only provided a basic overview, we highly recommend a deeper look on topics such as different versions of the wild bootstrap, since we only applied the Rademacher-version, as well as parametric bootstraps for specific problems. Also, many test-problems are of interest, for example multiple contrast tests, F-Test, Anderson-Darling, Kolmogorov-Smirnov or rank-based tests such as Mann-Whitney-U test and other effect-size tests. Even though there is a lot of research in that field, current problems in applied fields require new statistical methods as well. For example, the ongoing COVID-19-pandemic requires statistical tests for vaccines and treatments, as well as epidemiological test procedures for clusters of infected people. All of these begin with small samples (especially the first and second, until they reach phase II and III in the clinical trials). Thus, bootstrap is still a current issue of research and provides a lot of sub-topics to study.